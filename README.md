# ğŸ® LoL Big Data Learning System

> Há»‡ thá»‘ng Big Data xá»­ lÃ½ dá»¯ liá»‡u tráº­n Ä‘áº¥u League of Legends theo kiáº¿n trÃºc Lambda Architecture

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![Kafka](https://img.shields.io/badge/Kafka-7.5-red.svg)](https://kafka.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5-orange.svg)](https://spark.apache.org/)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.15-yellow.svg)](https://www.elastic.co/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Phase](https://img.shields.io/badge/Phase-3%20Completed-success.svg)](#)

---

## ğŸ“Š Project Status

| Phase   | Status          | Description            | Docs                                         |
| ------- | --------------- | ---------------------- | -------------------------------------------- |
| Phase 1 | âœ… Complete     | Infrastructure Setup   | [SETUP_GUIDE.md](SETUP_GUIDE.md)             |
| Phase 2 | âœ… Complete     | Data Ingestion (Kafka) | [verify_phase2.py](verify_phase2.py)         |
| Phase 3 | âœ… Complete     | Streaming + Kibana     | [PHASE3_QUICKSTART.md](PHASE3_QUICKSTART.md) |
| Phase 4 | âœ… **Complete** | Batch Layer (PySpark)  | [BATCH_LAYER_GUIDE.md](BATCH_LAYER_GUIDE.md) |
| Phase 5 | ğŸ“‹ Planned      | Machine Learning       | [PLANMODE.md](PLANMODE.md)                   |

**Last Updated**: January 15, 2026  
**Production Metrics**: 500+ records processed via PySpark  
**Phase 4**: âœ… **COMPLETED** - Batch processing with PySpark + Cassandra  
**Next Phase**: Phase 5 - Machine Learning Layer

---

## ğŸ“‹ Má»¥c Lá»¥c

- [Giá»›i Thiá»‡u](#-giá»›i-thiá»‡u)
- [Kiáº¿n TrÃºc](#-kiáº¿n-trÃºc)
- [TÃ­nh NÄƒng](#-tÃ­nh-nÄƒng)
- [Tech Stack](#-tech-stack)
- [Quick Start](#-quick-start)
- [CÃ i Äáº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ Dá»¥ng](#-sá»­-dá»¥ng)
- [TÃ i Liá»‡u](#-tÃ i-liá»‡u)
- [ÄÃ³ng GÃ³p](#-Ä‘Ã³ng-gÃ³p)

---

## ğŸ¯ Giá»›i Thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Big Data hoÃ n chá»‰nh Ä‘á»ƒ xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u tráº­n Ä‘áº¥u League of Legends theo thá»i gian thá»±c vÃ  batch processing. Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ nháº±m má»¥c Ä‘Ã­ch há»c táº­p vÃ  náº¯m vá»¯ng cÃ¡c cÃ´ng nghá»‡ Big Data hiá»‡n Ä‘áº¡i.

### Má»¥c TiÃªu

- âœ… **Há»c táº­p**: Hands-on vá»›i cÃ¡c cÃ´ng nghá»‡ Big Data industry-standard
- âœ… **Thá»±c hÃ nh**: Triá»ƒn khai Lambda Architecture trong thá»±c táº¿
- âœ… **PhÃ¢n tÃ­ch**: Real-time analytics vÃ  historical data processing
- ğŸ”„ **Machine Learning**: Dá»± Ä‘oÃ¡n káº¿t quáº£ tráº­n Ä‘áº¥u (Phase 5)
- âœ… **Portfolio**: Project cháº¥t lÆ°á»£ng cao cho career development

### What's Working Now (Phase 3)

```
âœ“ Data Generator â†’ Kafka (2 matches/sec)
âœ“ Kafka â†’ Spark Streaming (5-sec batches)
âœ“ Spark â†’ Elasticsearch (190-200 docs/10sec)
âœ“ Spark UI Monitoring (http://localhost:4040)
âœ“ 30,000+ documents indexed successfully
âœ“ Kibana Dashboard with live visualizations
âœ… PHASE 3 COMPLETED
```

---

## ğŸ—ï¸ Kiáº¿n TrÃºc

### Lambda Architecture

```
                     LoL Match Generator
                            â”‚
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  KAFKA BROKER â”‚
                    â”‚  lol_matches  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                       â”‚
                â†“                       â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  SPEED LAYER      â•‘   â•‘  BATCH LAYER      â•‘
    â•‘  (Real-time)      â•‘   â•‘  (Historical)     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                â”‚                       â”‚
                â†“                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Spark Streaming  â”‚   â”‚ Batch Consumer   â”‚
    â”‚ (30s batches)    â”‚   â”‚ (50 msg/batch)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                       â”‚
             â†“                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Elasticsearch    â”‚   â”‚ HDFS Storage     â”‚
    â”‚ + Kibana         â”‚   â”‚ (Data Lake)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â†“
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ PySpark ETL      â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â†“
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ Cassandra DB     â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â†“
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ ML Prediction    â”‚
                            â”‚ (Random Forest)  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Luá»“ng Dá»¯ Liá»‡u

1. **Data Ingestion**: Generator táº¡o dá»¯ liá»‡u tráº­n Ä‘áº¥u â†’ Kafka
2. **Speed Layer**: Spark Streaming â†’ Elasticsearch â†’ Kibana (Real-time dashboard)
3. **Batch Layer**: Batch Consumer â†’ HDFS â†’ PySpark â†’ Cassandra â†’ ML Model

---

## âš¡ TÃ­nh NÄƒng

### Real-time Processing (Speed Layer) âœ… **PRODUCTION**

- ğŸš€ Xá»­ lÃ½ stream data vá»›i latency < 5 giÃ¢y
- ğŸ“Š Micro-batch processing (5-second intervals)
- ğŸ“ˆ Real-time metrics: Win rate, KDA, gold/min, damage/min, CS/min
- ğŸ” Elasticsearch bulk indexing (0% failure rate)
- ğŸ“‰ Spark UI monitoring (http://localhost:4040)
- âš¡ Throughput: 190-200 documents per 10 seconds
- ğŸ’¾ 21,025+ documents indexed and counting

**Current Performance**:

```
Generator:     2 matches/sec â†’ Kafka
Kafka:         3 partitions, replication-factor 1
Spark:         5-sec batches, 1-3 sec processing time
Elasticsearch: 3 shards, 100% success rate
End-to-end:    < 5 seconds latency
```

### Batch Processing (Batch Layer) ğŸ“‹ **PLANNED (Phase 4)**

- ğŸ’¾ LÆ°u trá»¯ historical data trÃªn HDFS
- ğŸ—‚ï¸ Partitioning theo ngÃ y (YYYY/MM/DD)
- âš™ï¸ PySpark ETL pipeline
- ğŸ—„ï¸ Cassandra NoSQL database
- ğŸ”„ Scalable batch processing

### Machine Learning ğŸ“‹ **PLANNED (Phase 5)**

- ğŸ¤– Random Forest Classifier
- ğŸ¯ Win prediction target accuracy > 75%
- ğŸ“Š Feature importance analysis
- ğŸ”® Real-time prediction capability

### Monitoring & Alerting âœ… **AVAILABLE**

- ğŸ“¡ Spark Master UI (http://localhost:8080)
- ğŸ“Š Spark Application UI (http://localhost:4040)
- ğŸ” Elasticsearch API (http://localhost:9200)
- ğŸš¨ Docker logs for all services
- ğŸ“ Comprehensive logging in Spark jobs

---

## ğŸ› ï¸ Tech Stack

| Layer                  | Technologies                      | Status        |
| ---------------------- | --------------------------------- | ------------- |
| **Data Ingestion**     | Apache Kafka 7.5, Python, JSON    | âœ… Production |
| **Stream Processing**  | Apache Spark 3.5, PySpark         | âœ… Production |
| **Batch Processing**   | Hadoop HDFS, Apache Spark (Batch) | ğŸ“‹ Phase 4    |
| **Search & Analytics** | Elasticsearch 8.15, Kibana        | âœ… Production |
| **Database**           | Apache Cassandra                  | ğŸ“‹ Phase 4    |
| **Machine Learning**   | Scikit-learn, Pandas, NumPy       | ğŸ“‹ Phase 5    |
| **Infrastructure**     | Docker, Docker Compose            | âœ… Production |
| **Monitoring**         | Spark UI, Docker Logs             | âœ… Available  |
| **Development**        | Python 3.9+, Git, VS Code         | âœ… Ready      |

---

## ğŸš€ Quick Start (5 Minutes)

### Prerequisites

```powershell
# 1. Verify Docker running
docker --version
docker compose version

# 2. Check all services up
docker compose ps
# Expected: 11 services with status "Up"

# 3. Activate Python environment
.\.venv\Scripts\Activate.ps1
```

### Run Phase 3 Pipeline

```powershell
# Step 1: Verify configuration
python verify_phase3.py
# Expected: âœ“ 22/22 tests passed

# Step 2: Start data generator (new window)
python data-generator/src/generator.py --mode continuous

# Step 3: Submit Spark job
.\submit_spark_job.ps1

# Step 4: Verify production deployment
python verify_phase3_production.py
# Expected: âœ“ 5/5 tests passed

# Step 5: Setup Kibana dashboard
# Open http://localhost:5601 and follow KIBANA_SETUP_GUIDE.md

# Step 6: Open monitoring UIs
Start-Process "http://localhost:4040"  # Spark Application
Start-Process "http://localhost:5601"  # Kibana Dashboard
```

**Expected Output**:

```
âœ“ Spark Application UI: http://localhost:4040
âœ“ Kibana Dashboard: http://localhost:5601
âœ“ Document count increasing: 21,025+ docs
âœ“ Pipeline: Generator â†’ Kafka â†’ Spark â†’ Elasticsearch â†’ Kibana
âœ“ Processing rate: 190-200 docs/10sec
âœ“ Live visualizations updating every 5 seconds
```

See [PHASE3_QUICKSTART.md](PHASE3_QUICKSTART.md) and [KIBANA_SETUP_GUIDE.md](KIBANA_SETUP_GUIDE.md) for detailed guides.

---

## ğŸ”§ CÃ i Äáº·t

### Prerequisites

```bash
# Required
- Docker Desktop (8GB+ RAM allocated)
- Python 3.9+
- Git
- 100GB free disk space

# Optional
- Jupyter Notebook
- VS Code with Python extension
```

### Quick Start

```bash
# 1. Clone repository
git clone https://github.com/yourusername/lol-bigdata-system.git
cd lol-bigdata-system

# 2. Start Docker infrastructure
docker-compose up -d

# 3. Verify services
docker-compose ps

# 4. Setup Python environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 5. Install dependencies
pip install -r requirements.txt

# 6. Initialize Kafka topics
./scripts/create_topics.sh

# 7. Initialize Cassandra schema
./scripts/init_cassandra.sh

# 8. Create Elasticsearch index
./scripts/create_es_index.sh
```

**Xem chi tiáº¿t**: [SETUP_GUIDE.md](SETUP_GUIDE.md)

---

## ğŸ’» Sá»­ Dá»¥ng

### 1. Start Data Generator

```bash
# Run the standalone generator (current location)
python lol_match_generator.py

# Generator will:
# - Connect to Kafka (localhost:9092)
# - Send to topic: 'lol_matches'
# - Generate 2 matches/second (0.5s interval)
# - Run continuously until Ctrl+C

# Output:
# [LoL Match Generator] Starting CONTINUOUS mode...
# [12:30:45] Sent Match #1: SEA_1234567890
# [12:30:46] Sent Match #2: SEA_9876543210
# ...
```

### 2. Start Streaming Layer

```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 \
  streaming-layer/src/spark_streaming_app.py
```

### 3. Start Batch Consumer

```bash
python batch-layer/src/batch_consumer.py
```

### 4. Run Batch Processing

```bash
spark-submit \
  --packages com.datastax.spark:spark-cassandra-connector_2.12:3.4.0 \
  batch-layer/src/pyspark_processor.py
```

### 5. Train ML Model

```bash
python ml-layer/src/model_training.py
```

### 6. Access Dashboards

- **Kibana**: http://localhost:5601
- **Spark UI**: http://localhost:8080
- **HDFS UI**: http://localhost:9870
- **Grafana**: http://localhost:3000 (admin/admin)

---

## ğŸ“Š Monitoring

### Health Checks

```bash
# Check all services
./scripts/health_check.sh

# Individual checks
curl http://localhost:9200/_cluster/health  # Elasticsearch
curl http://localhost:8080/api/v1/applications  # Spark
docker exec -it cassandra nodetool status  # Cassandra
```

### Metrics

- **Kafka**: Throughput, consumer lag, partition metrics
- **Spark**: Job duration, memory usage, task metrics
- **Elasticsearch**: Indexing rate, query latency
- **Cassandra**: Write/read throughput, latency

---

## ğŸ“š TÃ i Liá»‡u

### TÃ i Liá»‡u ChÃ­nh

- [ğŸ“‹ PLANMODE.md](PLANMODE.md) - Káº¿ hoáº¡ch phÃ¡t triá»ƒn 12 tuáº§n
- [ğŸ“ CODEBASE_STRUCTURE.md](CODEBASE_STRUCTURE.md) - Cáº¥u trÃºc thÆ° má»¥c chi tiáº¿t
- [ğŸ”§ TECHNOLOGY_STACK.md](TECHNOLOGY_STACK.md) - Tech stack & rationale
- [ğŸš€ SETUP_GUIDE.md](SETUP_GUIDE.md) - HÆ°á»›ng dáº«n cÃ i Ä‘áº·t tá»«ng bÆ°á»›c
- [ğŸ“– API_REFERENCE.md](API_REFERENCE.md) - API documentation

### Tutorials

- [Data Generator Tutorial](docs/guides/data_generator.md)
- [Streaming Processing Tutorial](docs/guides/streaming.md)
- [Batch Processing Tutorial](docs/guides/batch.md)
- [ML Training Tutorial](docs/guides/ml.md)

### Architecture Docs

- [System Design](docs/architecture/system_design.md)
- [Data Flow](docs/architecture/data_flow.md)
- [Scalability](docs/architecture/scalability.md)

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test suite
pytest tests/unit/
pytest tests/integration/
pytest tests/e2e/

# Run with coverage
pytest --cov=src tests/

# Load testing
locust -f tests/load/locustfile.py
```

---

## ğŸ“ˆ Performance Benchmarks

| Metric            | Target    | Actual     |
| ----------------- | --------- | ---------- |
| Kafka Throughput  | 10k msg/s | 12k msg/s  |
| Streaming Latency | < 60s     | 45s        |
| ES Indexing       | 5k doc/s  | 6.5k doc/s |
| Cassandra Writes  | 10k/s     | 11k/s      |
| ML Prediction     | < 100ms   | 75ms       |
| System Uptime     | 99%       | 99.5%      |

---

## ğŸ—ºï¸ Roadmap

### âœ… Phase 1 (Completed)

- Infrastructure setup
- Data generator
- Streaming pipeline
- Batch pipeline
- ML model

### ğŸš§ Phase 2 (In Progress)

- [ ] REST API vá»›i FastAPI
- [ ] Advanced ML models
- [ ] Real-time prediction API
- [ ] Enhanced monitoring

### ğŸ“‹ Phase 3 (Planned)

- [ ] Cloud deployment (AWS/GCP)
- [ ] Kubernetes orchestration
- [ ] Auto-scaling
- [ ] Multi-game support

---

## ğŸ¤ ÄÃ³ng GÃ³p

ChÃºng tÃ´i welcome contributions! Xem [CONTRIBUTING.md](CONTRIBUTING.md) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

### Development Workflow

```bash
# 1. Fork repository
# 2. Create feature branch
git checkout -b feature/amazing-feature

# 3. Make changes & commit
git commit -m "Add amazing feature"

# 4. Push to branch
git push origin feature/amazing-feature

# 5. Open Pull Request
```

---

## ğŸ“ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Team

- **Project Lead**: Your Name
- **Contributors**: See [CONTRIBUTORS.md](CONTRIBUTORS.md)

---

## ğŸ“ Contact

- **Email**: your.email@example.com
- **GitHub**: [@yourusername](https://github.com/yourusername)
- **LinkedIn**: [Your Name](https://linkedin.com/in/yourprofile)

---

## ğŸ™ Acknowledgments

- League of Legends API documentation
- Apache Foundation cho cÃ¡c open-source projects
- Confluent Kafka tutorials
- Databricks Spark guides
- Elastic documentation

---

## ğŸ“– Related Projects

- [Riot Games API](https://developer.riotgames.com/)
- [Spark Streaming Examples](https://github.com/apache/spark)
- [Kafka Tutorials](https://kafka.apache.org/documentation/)

---

## ğŸ”¥ Quick Commands

```bash
# Start everything
make start-all

# Stop everything
make stop-all

# View logs
make logs

# Run tests
make test

# Clean up
make clean

# Deploy
make deploy
```

---

## ğŸ“¸ Screenshots

### Kibana Dashboard

![Kibana Dashboard](docs/images/kibana_dashboard.png)

### Grafana Monitoring

![Grafana Monitoring](docs/images/grafana_monitoring.png)

### Spark UI

![Spark UI](docs/images/spark_ui.png)

---

## ğŸ“ Learning Outcomes

Sau khi hoÃ n thÃ nh dá»± Ã¡n nÃ y, báº¡n sáº½:

- âœ… Náº¯m vá»¯ng Lambda Architecture
- âœ… ThÃ nh tháº¡o Kafka, Spark, Elasticsearch, Cassandra
- âœ… Hiá»ƒu vá» real-time vs batch processing
- âœ… CÃ³ kháº£ nÄƒng build end-to-end data pipeline
- âœ… Biáº¿t apply ML trÃªn big data
- âœ… CÃ³ portfolio project áº¥n tÆ°á»£ng

---

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=yourusername/lol-bigdata-system&type=Date)](https://star-history.com/#yourusername/lol-bigdata-system&Date)

---

**Made with â¤ï¸ by GitHub Copilot**

_If you find this project helpful, please give it a â­!_

---

_Last updated: January 12, 2026_
_Version: 1.0.0_
