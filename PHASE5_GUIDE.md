# PHASE 5 GUIDE: Machine Learning Layer - SIMPLE PROOF-OF-CONCEPT

## üìã Overview

**Goal**: Demo lu·ªìng ML pipeline ho·∫°t ƒë·ªông - KH√îNG c·∫ßn model t·ªët hay features ph·ª©c t·∫°p

**Timeline**: 1-2 gi·ªù (c√≥ th·ªÉ ho√†n th√†nh trong 30-60 ph√∫t)

**Philosophy**: **ƒê∆†N GI·∫¢N H√ìA T·ªêI ƒêA** - ch·ªâ c·∫ßn:
- ‚úÖ Load data t·ª´ Cassandra
- ‚úÖ Train model ƒë∆°n gi·∫£n (Logistic Regression)
- ‚úÖ Save model
- ‚úÖ Test prediction
- ‚ùå KH√îNG c·∫ßn: high accuracy, visualization, feature engineering ph·ª©c t·∫°p

---

## üöÄ QUICK START - 5 B∆Ø·ªöC ƒê∆†N GI·∫¢N

### B∆∞·ªõc 1: Install (10 gi√¢y)

```bash
# Activate virtual environment
.\.venv\Scripts\Activate.ps1

# Install ONLY 3 packages
pip install scikit-learn pandas cassandra-driver

# Verify
python -c "import sklearn, pandas; print('‚úÖ Ready!')"
```

### B∆∞·ªõc 2: T·∫°o folders (5 gi√¢y)

```powershell
New-Item -ItemType Directory -Force -Path ml-layer\src
New-Item -ItemType Directory -Force -Path ml-layer\models
```

### B∆∞·ªõc 3: Code Training Script (Copy paste)

T·∫°o file `ml-layer/src/train_model.py`:

```python
"""
SIMPLE ML Training - Phase 5 Proof-of-Concept
Ch·ªâ c·∫ßn train ƒë∆∞·ª£c v√† save model l√† ƒë·ªß
"""
from cassandra.cluster import Cluster
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import pickle

print("=" * 60)
print("PHASE 5: SIMPLE ML TRAINING")
print("=" * 60)

# 1. Connect to Cassandra
print("\n[1/5] Connecting to Cassandra...")
cluster = Cluster(['localhost'])
session = cluster.connect('lol_data')
print("‚úÖ Connected")

# 2. Load data (CH·ªà L·∫§Y 100 RECORDS - ƒë·ªß r·ªìi)
print("\n[2/5] Loading data...")
query = "SELECT kills, deaths, assists, gold_earned, win FROM match_participants LIMIT 100"
rows = session.execute(query)
df = pd.DataFrame(rows)
print(f"‚úÖ Loaded {len(df)} records")
print(f"   Columns: {list(df.columns)}")

# 3. Prepare features (ƒê∆†N GI·∫¢N - ch·ªâ 4 features)
print("\n[3/5] Preparing features...")
X = df[['kills', 'deaths', 'assists', 'gold_earned']]
y = df['win']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
print(f"‚úÖ Train: {len(X_train)}, Test: {len(X_test)}")

# 4. Train model (SIMPLE - Logistic Regression)
print("\n[4/5] Training model...")
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Test accuracy
accuracy = model.score(X_test, y_test)
print(f"‚úÖ Model trained!")
print(f"   Accuracy: {accuracy:.2%}")

# Show some predictions
print("\n   Sample predictions:")
predictions = model.predict(X_test[:5])
actuals = y_test.iloc[:5].values
for i in range(5):
    pred_label = "WIN" if predictions[i] else "LOSS"
    actual_label = "WIN" if actuals[i] else "LOSS"
    match = "‚úÖ" if predictions[i] == actuals[i] else "‚ùå"
    print(f"   {match} Predicted: {pred_label}, Actual: {actual_label}")

# 5. Save model
print("\n[5/5] Saving model...")
with open('ml-layer/models/win_predictor.pkl', 'wb') as f:
    pickle.dump(model, f)
print("‚úÖ Model saved to: ml-layer/models/win_predictor.pkl")

# Cleanup
cluster.shutdown()

print("\n" + "=" * 60)
print("‚úÖ PHASE 5 TRAINING COMPLETE!")
print("=" * 60)
print("\nNext: Run prediction script")
print("python ml-layer/src/predict.py")
```

### B∆∞·ªõc 4: Code Prediction Script (Copy paste)

T·∫°o file `ml-layer/src/predict.py`:

```python
"""
SIMPLE Prediction Script - Test saved model
"""
import pickle
import pandas as pd

print("=" * 60)
print("TESTING SAVED MODEL")
print("=" * 60)

# 1. Load model
print("\n[1/3] Loading model...")
with open('ml-layer/models/win_predictor.pkl', 'rb') as f:
    model = pickle.load(f)
print("‚úÖ Model loaded")

# 2. Test data (Fake data cho ƒë∆°n gi·∫£n)
print("\n[2/3] Creating test data...")
test_data = pd.DataFrame({
    'kills': [10, 2, 5],
    'deaths': [2, 8, 5],
    'assists': [15, 3, 8],
    'gold_earned': [12000, 8000, 10000]
})
print("‚úÖ Test data ready")

# 3. Predict
print("\n[3/3] Making predictions...")
predictions = model.predict(test_data)
probabilities = model.predict_proba(test_data)

print("\n" + "=" * 60)
print("PREDICTION RESULTS")
print("=" * 60)

for i in range(len(test_data)):
    kills = test_data.iloc[i]['kills']
    deaths = test_data.iloc[i]['deaths']
    assists = test_data.iloc[i]['assists']
    gold = test_data.iloc[i]['gold_earned']
    
    pred = "WIN" if predictions[i] else "LOSS"
    prob_win = probabilities[i][1] * 100
    prob_loss = probabilities[i][0] * 100
    
    print(f"\nTest Case {i+1}:")
    print(f"  Stats: {kills}K / {deaths}D / {assists}A, {gold:,} gold")
    print(f"  Prediction: {pred}")
    print(f"  Confidence: Win {prob_win:.1f}% | Loss {prob_loss:.1f}%")

print("\n" + "=" * 60)
print("‚úÖ PHASE 5 COMPLETE - ML PIPELINE WORKING!")
print("=" * 60)
```

### B∆∞·ªõc 5: Run! (1 ph√∫t)

```bash
# Train model
python ml-layer/src/train_model.py
# Expected output:
# ‚úÖ Model trained! Accuracy: 55-65%
# ‚úÖ Model saved

# Test prediction
python ml-layer/src/predict.py
# Expected output:
# ‚úÖ 3 predictions with Win/Loss results
```

---

## ‚úÖ HO√ÄN T·∫§T!

**B·∫°n ƒë√£ c√≥:**
- ‚úÖ ML pipeline ho·∫°t ƒë·ªông (Cassandra ‚Üí Train ‚Üí Save ‚Üí Predict)
- ‚úÖ Model file: `ml-layer/models/win_predictor.pkl`
- ‚úÖ 2 Python scripts: `train_model.py`, `predict.py`
- ‚úÖ Test predictions ƒë√£ ch·∫°y th√†nh c√¥ng

**Accuracy bao nhi√™u?**
- 55-65% l√† OK (cao h∆°n random 50%)
- KH√îNG C·∫¶N 75-80% - ƒë√¢y ch·ªâ l√† demo

**Phase 5 K·∫æT TH√öC ƒê√ÇY!**

---

## üîß Troubleshooting (N·∫øu l·ªói)

### L·ªói: Cannot connect to Cassandra

```bash
# Check Cassandra running
docker ps | findstr cassandra

# Restart if needed
docker restart cassandra
Start-Sleep -Seconds 30
```

### L·ªói: No data in Cassandra

```bash
# Check data exists
docker exec cassandra cqlsh -e "SELECT COUNT(*) FROM lol_data.match_participants;"

# If 0 records, rerun Phase 4:
python batch-layer/src/batch_consumer.py --batches 1
# Then run PySpark ETL to load into Cassandra
```

### L·ªói: sklearn not found

```bash
pip install --upgrade scikit-learn
```

---

## üìù CH√ö √ù QUAN TR·ªåNG

### ‚úÖ ƒê∆Ø·ª¢C PH√âP (Simple):
- Accuracy 50-60% (ch·ªâ c·∫ßn > random)
- Ch·ªâ 3-5 features
- Hardcode values
- Kh√¥ng c·∫ßn visualization
- Kh√¥ng c·∫ßn config files
- Code copy-paste t·ª´ guide n√†y

### ‚ùå KH√îNG C·∫¶N (Qu√° ph·ª©c t·∫°p):
- Jupyter notebooks
- Feature engineering ph·ª©c t·∫°p
- Cross-validation
- Hyperparameter tuning
- Model comparison (Random Forest, XGBoost)
- Feature importance plots
- ROC-AUC curves
- MLflow tracking
- Prediction API
- Unit tests

**M·ª•c ti√™u**: Hi·ªÉu ML pipeline flow, KH√îNG PH·∫¢I build production model!

---

## üéØ Phase 5 Completion Checklist

- [ ] Install 3 packages: scikit-learn, pandas, cassandra-driver
- [ ] Create 2 folders: ml-layer/src, ml-layer/models
- [ ] Copy 2 Python files: train_model.py, predict.py
- [ ] Run training: `python ml-layer/src/train_model.py`
- [ ] Run prediction: `python ml-layer/src/predict.py`
- [ ] See 3 predictions printed

**T·ªïng th·ªùi gian**: 30-60 ph√∫t (n·∫øu kh√¥ng l·ªói)

**N·∫øu 6/6 tasks ‚úÖ ‚Üí Phase 5 DONE!**

---

**Created**: January 13, 2026  
**Version**: 2.0 - Ultra Simple Proof-of-Concept  
**Author**: GitHub Copilot  
**Time**: 30-60 minutes  
**Difficulty**: Very Easy (Copy-paste code)

---

## üéØ Phase 5 Option A - Simple MVP Roadmap

### Day 1: Setup & Data Exploration

#### Morning Session (2-3 hours)

**1.1 Install ML Dependencies**

```bash
# Activate virtual environment
.\.venv\Scripts\Activate.ps1

# Install ML packages
pip install scikit-learn==1.3.2
pip install xgboost==2.0.3
pip install mlflow==2.9.2
pip install jupyter==1.0.0
pip install matplotlib==3.8.2
pip install seaborn==0.13.0
pip install shap==0.44.0
pip install pandas==2.1.4
pip install numpy==1.26.2

# Verify installation
python -c "import sklearn, xgboost, mlflow, jupyter; print('‚úÖ All packages installed')"
```

**1.2 Create Directory Structure**

```bash
# Create ml-layer folders
New-Item -ItemType Directory -Force -Path ml-layer\notebooks
New-Item -ItemType Directory -Force -Path ml-layer\src
New-Item -ItemType Directory -Force -Path ml-layer\models
New-Item -ItemType Directory -Force -Path ml-layer\config
New-Item -ItemType Directory -Force -Path ml-layer\tests
New-Item -ItemType Directory -Force -Path ml-layer\mlflow

# Create __init__.py files
New-Item -ItemType File -Force -Path ml-layer\src\__init__.py
New-Item -ItemType File -Force -Path ml-layer\tests\__init__.py

# Create requirements.txt
@"
scikit-learn==1.3.2
xgboost==2.0.3
mlflow==2.9.2
jupyter==1.0.0
matplotlib==3.8.2
seaborn==0.13.0
shap==0.44.0
pandas==2.1.4
numpy==1.26.2
cassandra-driver==3.29.0
"@ | Out-File -FilePath ml-layer\requirements.txt -Encoding utf8
```

**1.3 Test Cassandra Connection**

Create `ml-layer/src/data_loader.py`:

```python
"""
Data loader for ML pipeline - loads data from Cassandra
"""
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
import pandas as pd
from typing import Optional, Tuple
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CassandraDataLoader:
    """Load data from Cassandra for ML pipeline"""
    
    def __init__(self, contact_points=['localhost'], port=9042):
        """Initialize Cassandra connection"""
        self.contact_points = contact_points
        self.port = port
        self.cluster = None
        self.session = None
        
    def connect(self):
        """Connect to Cassandra cluster"""
        try:
            self.cluster = Cluster(self.contact_points, port=self.port)
            self.session = self.cluster.connect('lol_data')
            logger.info("‚úÖ Connected to Cassandra")
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to Cassandra: {e}")
            raise
            
    def disconnect(self):
        """Close Cassandra connection"""
        if self.cluster:
            self.cluster.shutdown()
            logger.info("Disconnected from Cassandra")
    
    def load_match_participants(self, limit: Optional[int] = None) -> pd.DataFrame:
        """
        Load match participants data
        
        Args:
            limit: Optional limit on number of records
            
        Returns:
            DataFrame with match participant data
        """
        query = "SELECT * FROM match_participants"
        if limit:
            query += f" LIMIT {limit}"
            
        try:
            rows = self.session.execute(query)
            df = pd.DataFrame(rows)
            logger.info(f"‚úÖ Loaded {len(df)} match participants")
            return df
        except Exception as e:
            logger.error(f"‚ùå Failed to load match participants: {e}")
            raise
            
    def load_champion_stats(self) -> pd.DataFrame:
        """Load aggregated champion statistics"""
        query = "SELECT * FROM champion_stats"
        try:
            rows = self.session.execute(query)
            df = pd.DataFrame(rows)
            logger.info(f"‚úÖ Loaded {len(df)} champion stats")
            return df
        except Exception as e:
            logger.error(f"‚ùå Failed to load champion stats: {e}")
            raise
            
    def load_position_stats(self) -> pd.DataFrame:
        """Load aggregated position statistics"""
        query = "SELECT * FROM position_stats"
        try:
            rows = self.session.execute(query)
            df = pd.DataFrame(rows)
            logger.info(f"‚úÖ Loaded {len(df)} position stats")
            return df
        except Exception as e:
            logger.error(f"‚ùå Failed to load position stats: {e}")
            raise
            
    def load_all_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        Load all data for ML pipeline
        
        Returns:
            Tuple of (match_participants, champion_stats, position_stats)
        """
        participants = self.load_match_participants()
        champions = self.load_champion_stats()
        positions = self.load_position_stats()
        
        logger.info(f"""
        üìä Data loaded:
           - Match Participants: {len(participants)} records
           - Champion Stats: {len(champions)} champions
           - Position Stats: {len(positions)} positions
        """)
        
        return participants, champions, positions


def test_connection():
    """Test Cassandra connection"""
    loader = CassandraDataLoader()
    try:
        loader.connect()
        
        # Load sample data
        df_participants, df_champions, df_positions = loader.load_all_data()
        
        # Print summary
        print("\n" + "="*60)
        print("üìä CASSANDRA DATA SUMMARY")
        print("="*60)
        print(f"\n1Ô∏è‚É£ Match Participants: {len(df_participants)} records")
        print(f"   Columns: {list(df_participants.columns)[:5]}...")
        print(f"\n2Ô∏è‚É£ Champion Stats: {len(df_champions)} champions")
        print(df_champions[['champion_name', 'games_played', 'win_rate', 'avg_kda']].head(3))
        print(f"\n3Ô∏è‚É£ Position Stats: {len(df_positions)} positions")
        print(df_positions[['position', 'games_played', 'avg_win_rate']])
        print("\n" + "="*60)
        print("‚úÖ Connection test PASSED")
        print("="*60 + "\n")
        
    finally:
        loader.disconnect()


if __name__ == "__main__":
    test_connection()
```

Test the connection:

```bash
python ml-layer/src/data_loader.py
# Expected: ‚úÖ Connected, loaded 500 participants, 36 champions, 5 positions
```

#### Afternoon Session (3-4 hours)

**1.4 Data Exploration Notebook**

Start Jupyter:

```bash
cd ml-layer/notebooks
jupyter notebook
```

Create `01_data_exploration.ipynb`:

```python
# Cell 1: Setup
import sys
sys.path.append('../src')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from data_loader import CassandraDataLoader

# Set plotting style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

print("‚úÖ Imports successful")

# Cell 2: Load Data
loader = CassandraDataLoader()
loader.connect()

df_participants, df_champions, df_positions = loader.load_all_data()

loader.disconnect()

print(f"""
üìä Data Loaded:
   - Participants: {len(df_participants)} rows √ó {len(df_participants.columns)} cols
   - Champions: {len(df_champions)} rows
   - Positions: {len(df_positions)} rows
""")

# Cell 3: Basic Info
print("üîç Match Participants Schema:")
print(df_participants.dtypes)
print("\nüìà Basic Statistics:")
print(df_participants.describe())

# Cell 4: Check Missing Values
print("‚ùì Missing Values:")
missing = df_participants.isnull().sum()
print(missing[missing > 0] if missing.sum() > 0 else "‚úÖ No missing values!")

# Cell 5: Target Distribution
print("üéØ Win Rate Distribution:")
win_rate = df_participants['win'].mean()
print(f"Overall Win Rate: {win_rate:.2%}")
print(f"Wins: {df_participants['win'].sum()}")
print(f"Losses: {len(df_participants) - df_participants['win'].sum()}")

plt.figure(figsize=(8, 6))
df_participants['win'].value_counts().plot(kind='bar', color=['red', 'green'])
plt.title('Win/Loss Distribution')
plt.xlabel('Result (0=Loss, 1=Win)')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

# Cell 6: Champion Performance
print("üèÜ Top 10 Champions by Win Rate:")
top_champions = df_champions.nlargest(10, 'win_rate')
print(top_champions[['champion_name', 'games_played', 'win_rate', 'avg_kda', 'avg_gpm']])

plt.figure(figsize=(12, 6))
plt.barh(top_champions['champion_name'], top_champions['win_rate'])
plt.xlabel('Win Rate')
plt.title('Top 10 Champions by Win Rate')
plt.tight_layout()
plt.show()

# Cell 7: Position Analysis
print("üìç Position Performance:")
print(df_positions[['position', 'games_played', 'avg_win_rate', 'avg_gpm', 'avg_kda']])

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

df_positions.plot(x='position', y='avg_win_rate', kind='bar', ax=axes[0], legend=False)
axes[0].set_title('Win Rate by Position')
axes[0].set_ylabel('Win Rate')

df_positions.plot(x='position', y='avg_gpm', kind='bar', ax=axes[1], legend=False, color='orange')
axes[1].set_title('Gold per Minute by Position')
axes[1].set_ylabel('GPM')

df_positions.plot(x='position', y='avg_kda', kind='bar', ax=axes[2], legend=False, color='green')
axes[2].set_title('KDA by Position')
axes[2].set_ylabel('KDA')

plt.tight_layout()
plt.show()

# Cell 8: Feature Correlations
print("üîó Feature Correlations with Win:")

# Select numeric columns
numeric_cols = ['kills', 'deaths', 'assists', 'gold_earned', 'total_damage_dealt',
                'total_minions_killed', 'vision_score', 'gold_per_minute', 
                'damage_per_minute', 'cs_per_minute', 'kill_participation']

correlations = df_participants[numeric_cols + ['win']].corr()['win'].sort_values(ascending=False)
print(correlations)

plt.figure(figsize=(10, 8))
sns.heatmap(df_participants[numeric_cols + ['win']].corr(), 
            annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.show()

# Cell 9: Key Insights
print("""
üìù KEY INSIGHTS FOR MODEL:

1. Data Quality:
   - {records} records available
   - No missing values
   - Balanced win/loss distribution

2. Important Features:
   - High correlation: {top_feature}
   - Good predictors: kills, assists, gold, damage
   - Derived features: KDA, GPM, DPM working well

3. Champion Impact:
   - Top win rate: {best_champion} ({best_wr:.1%})
   - Champion selection matters for predictions

4. Position Patterns:
   - {best_position} highest GPM ({best_gpm:.0f})
   - Position-specific strategies exist

5. Model Strategy:
   - Use individual performance metrics
   - Include champion identity (one-hot encoding)
   - Add position information
   - Consider time features (hour, weekend)
""".format(
    records=len(df_participants),
    top_feature=correlations.index[1],
    best_champion=top_champions.iloc[0]['champion_name'],
    best_wr=top_champions.iloc[0]['win_rate'],
    best_position=df_positions.loc[df_positions['avg_gpm'].idxmax(), 'position'],
    best_gpm=df_positions['avg_gpm'].max()
))

# Cell 10: Save for Next Step
print("üíæ Saving data for feature engineering...")
df_participants.to_pickle('../data_cache_participants.pkl')
df_champions.to_pickle('../data_cache_champions.pkl')
df_positions.to_pickle('../data_cache_positions.pkl')
print("‚úÖ Data saved!")
```

**Expected Outcomes:**
- ‚úÖ 500 participants loaded
- ‚úÖ Visualizations showing champion/position performance
- ‚úÖ Correlation analysis identifying key features
- ‚úÖ Data saved for feature engineering

---

### Day 2: Feature Engineering & Model Training

#### Morning Session (3-4 hours)

**2.1 Feature Engineering Notebook**

Create `02_feature_engineering.ipynb`:

```python
# Cell 1: Setup
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

print("‚úÖ Imports successful")

# Cell 2: Load Data
print("üìÇ Loading cached data...")
df = pd.read_pickle('../data_cache_participants.pkl')
df_champions = pd.read_pickle('../data_cache_champions.pkl')
df_positions = pd.read_pickle('../data_cache_positions.pkl')

print(f"Loaded {len(df)} records")

# Cell 3: Select Features
print("üéØ Selecting features for model...")

# Numeric features (already engineered in Phase 4)
numeric_features = [
    'kills', 'deaths', 'assists',
    'gold_earned', 'total_damage_dealt', 'total_minions_killed',
    'vision_score', 'gold_per_minute', 'damage_per_minute',
    'cs_per_minute', 'kill_participation'
]

# Categorical features
categorical_features = ['champion_name', 'position']

# Time features
time_features = ['match_hour', 'match_day_of_week', 'is_weekend']

# Target
target = 'win'

print(f"""
Feature Groups:
- Numeric: {len(numeric_features)} features
- Categorical: {len(categorical_features)} features
- Time: {len(time_features)} features
- Target: {target}
""")

# Cell 4: Feature Engineering
print("üîß Engineering additional features...")

# Create KDA (already have kill_participation)
df['kda_ratio'] = (df['kills'] + df['assists']) / (df['deaths'] + 1)

# Add to numeric features
numeric_features.append('kda_ratio')

# Champion win rate (from aggregated stats)
champion_wr_map = df_champions.set_index('champion_name')['win_rate'].to_dict()
df['champion_win_rate'] = df['champion_name'].map(champion_wr_map)
numeric_features.append('champion_win_rate')

# Position average stats
position_gpm_map = df_positions.set_index('position')['avg_gpm'].to_dict()
df['position_avg_gpm'] = df['position'].map(position_gpm_map)
numeric_features.append('position_avg_gpm')

print(f"‚úÖ Added 3 engineered features")
print(f"Total numeric features: {len(numeric_features)}")

# Cell 5: Handle Categorical Features
print("üè∑Ô∏è Encoding categorical features...")

# One-hot encode champion and position
df_encoded = pd.get_dummies(df, columns=['champion_name', 'position'], prefix=['champ', 'pos'])

# Get feature columns
feature_cols = [col for col in df_encoded.columns 
                if col.startswith('champ_') or col.startswith('pos_') or col in numeric_features + time_features]

X = df_encoded[feature_cols]
y = df_encoded[target]

print(f"""
Encoding Results:
- Total features: {len(feature_cols)}
- Champion dummies: {len([c for c in feature_cols if c.startswith('champ_')])}
- Position dummies: {len([c for c in feature_cols if c.startswith('pos_')])}
- Numeric features: {len([c for c in feature_cols if c in numeric_features])}
- Time features: {len([c for c in feature_cols if c in time_features])}
""")

# Cell 6: Train/Test Split
print("‚úÇÔ∏è Splitting data...")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"""
Split Results:
- Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)
- Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)
- Train win rate: {y_train.mean():.2%}
- Test win rate: {y_test.mean():.2%}
""")

# Cell 7: Feature Scaling
print("üìè Scaling numeric features...")

# Only scale numeric features (not one-hot encoded)
numeric_feature_indices = [i for i, col in enumerate(feature_cols) if col in numeric_features]

scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

X_train_scaled.iloc[:, numeric_feature_indices] = scaler.fit_transform(
    X_train.iloc[:, numeric_feature_indices]
)
X_test_scaled.iloc[:, numeric_feature_indices] = scaler.transform(
    X_test.iloc[:, numeric_feature_indices]
)

print("‚úÖ Scaling complete")

# Cell 8: Save Processed Data
print("üíæ Saving processed data and artifacts...")

# Save train/test sets
with open('../ml_data_processed.pkl', 'wb') as f:
    pickle.dump({
        'X_train': X_train_scaled,
        'X_test': X_test_scaled,
        'y_train': y_train,
        'y_test': y_test,
        'feature_cols': feature_cols,
        'numeric_features': numeric_features,
        'time_features': time_features
    }, f)

# Save scaler
with open('../models/feature_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("‚úÖ Saved processed data and scaler")

# Cell 9: Feature Summary
print("""
üìã FEATURE ENGINEERING SUMMARY:

‚úÖ Completed Tasks:
1. Selected 11 base numeric features
2. Added 3 engineered features (KDA, champion WR, position avg GPM)
3. One-hot encoded champions (36 dummies)
4. One-hot encoded positions (5 dummies)
5. Included time features (3 features)
6. Train/test split (80/20)
7. Feature scaling (StandardScaler)

üìä Final Feature Set:
- Total features: {total}
- Ready for model training

üéØ Next Step: Model Training (03_model_training.ipynb)
""".format(total=len(feature_cols)))
```

**Expected Outcomes:**
- ‚úÖ ~58 features created (14 numeric + 36 champions + 5 positions + 3 time)
- ‚úÖ Train/test split (400/100 samples)
- ‚úÖ Scaler saved for deployment

#### Afternoon Session (3-4 hours)

**2.2 Model Training Notebook**

Create `03_model_training.ipynb`:

```python
# Cell 1: Setup
import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, roc_auc_score
)
from sklearn.model_selection import cross_val_score

print("‚úÖ Imports successful")

# Cell 2: Load Processed Data
print("üìÇ Loading processed data...")
with open('../ml_data_processed.pkl', 'rb') as f:
    data = pickle.load(f)

X_train = data['X_train']
X_test = data['X_test']
y_train = data['y_train']
y_test = data['y_test']
feature_cols = data['feature_cols']

print(f"""
Data Loaded:
- Training: {len(X_train)} samples
- Test: {len(X_test)} samples
- Features: {len(feature_cols)}
""")

# Cell 3: Baseline Model - Logistic Regression
print("üéØ Training Baseline Model (Logistic Regression)...")

lr_model = LogisticRegression(random_state=42, max_iter=1000)
lr_model.fit(X_train, y_train)

# Predictions
y_pred_lr = lr_model.predict(X_test)
y_proba_lr = lr_model.predict_proba(X_test)[:, 1]

# Metrics
lr_accuracy = accuracy_score(y_test, y_pred_lr)
lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)
lr_auc = roc_auc_score(y_test, y_proba_lr)

print(f"""
‚úÖ Logistic Regression Results:
   - Accuracy: {lr_accuracy:.4f}
   - Precision: {lr_precision:.4f}
   - Recall: {lr_recall:.4f}
   - F1 Score: {lr_f1:.4f}
   - ROC-AUC: {lr_auc:.4f}
""")

# Cell 4: Confusion Matrix - Logistic Regression
cm_lr = confusion_matrix(y_test, y_pred_lr)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

print(classification_report(y_test, y_pred_lr, target_names=['Loss', 'Win']))

# Cell 5: Random Forest Model
print("üå≥ Training Random Forest Model...")

rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train, y_train)

# Predictions
y_pred_rf = rf_model.predict(X_test)
y_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# Metrics
rf_accuracy = accuracy_score(y_test, y_pred_rf)
rf_precision = precision_score(y_test, y_pred_rf)
rf_recall = recall_score(y_test, y_pred_rf)
rf_f1 = f1_score(y_test, y_pred_rf)
rf_auc = roc_auc_score(y_test, y_proba_rf)

print(f"""
‚úÖ Random Forest Results:
   - Accuracy: {rf_accuracy:.4f}
   - Precision: {rf_precision:.4f}
   - Recall: {rf_recall:.4f}
   - F1 Score: {rf_f1:.4f}
   - ROC-AUC: {rf_auc:.4f}
""")

# Cell 6: Confusion Matrix - Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix - Random Forest')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

print(classification_report(y_test, y_pred_rf, target_names=['Loss', 'Win']))

# Cell 7: Model Comparison
print("üìä Model Comparison:")

comparison = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest'],
    'Accuracy': [lr_accuracy, rf_accuracy],
    'Precision': [lr_precision, rf_precision],
    'Recall': [lr_recall, rf_recall],
    'F1 Score': [lr_f1, rf_f1],
    'ROC-AUC': [lr_auc, rf_auc]
})

print(comparison)

# Visualization
comparison.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1 Score']].plot(
    kind='bar', figsize=(12, 6), rot=0
)
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

# Cell 8: ROC Curves
print("üìà ROC Curve Comparison:")

plt.figure(figsize=(10, 8))

# Logistic Regression ROC
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {lr_auc:.3f})', linewidth=2)

# Random Forest ROC
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.3f})', linewidth=2)

# Diagonal
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# Cell 9: Feature Importance (Random Forest)
print("üîç Feature Importance Analysis:")

# Get top 20 features
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False).head(20)

print(feature_importance)

plt.figure(figsize=(10, 8))
plt.barh(feature_importance['feature'], feature_importance['importance'])
plt.xlabel('Importance')
plt.title('Top 20 Feature Importances (Random Forest)')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# Cell 10: Cross-Validation
print("üîÑ Cross-Validation (5-fold)...")

# Logistic Regression CV
lr_cv_scores = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='accuracy')
print(f"Logistic Regression CV: {lr_cv_scores.mean():.4f} (+/- {lr_cv_scores.std() * 2:.4f})")

# Random Forest CV
rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')
print(f"Random Forest CV: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std() * 2:.4f})")

# Cell 11: Select Best Model
print("üèÜ Selecting Best Model...")

best_model = rf_model if rf_accuracy > lr_accuracy else lr_model
best_model_name = 'Random Forest' if rf_accuracy > lr_accuracy else 'Logistic Regression'

print(f"Selected: {best_model_name} (Accuracy: {max(rf_accuracy, lr_accuracy):.4f})")

# Cell 12: Save Best Model
print("üíæ Saving model...")

with open('../models/win_predictor_v1.pkl', 'wb') as f:
    pickle.dump({
        'model': best_model,
        'model_name': best_model_name,
        'feature_cols': feature_cols,
        'accuracy': max(rf_accuracy, lr_accuracy),
        'f1_score': rf_f1 if rf_accuracy > lr_accuracy else lr_f1,
        'training_date': pd.Timestamp.now().isoformat()
    }, f)

print("‚úÖ Model saved to ../models/win_predictor_v1.pkl")

# Cell 13: Model Summary
print(f"""
{'='*60}
üéâ MODEL TRAINING COMPLETE
{'='*60}

üìä Final Results:

Best Model: {best_model_name}
- Accuracy: {max(rf_accuracy, lr_accuracy):.2%}
- Precision: {max(rf_precision, lr_precision):.2%}
- Recall: {max(rf_recall, lr_recall):.2%}
- F1 Score: {max(rf_f1, lr_f1):.2%}
- ROC-AUC: {max(rf_auc, lr_auc):.2%}

‚úÖ Model meets target (‚â•75% accuracy): {'YES' if max(rf_accuracy, lr_accuracy) >= 0.75 else 'NO'}

üì¶ Saved Artifacts:
- Model: models/win_predictor_v1.pkl
- Scaler: models/feature_scaler.pkl
- Processed data: ml_data_processed.pkl

üéØ Next Steps:
1. Test prediction on new data
2. Deploy prediction script
3. Create verification script
4. Document performance

{'='*60}
""")
```

**Expected Outcomes:**
- ‚úÖ Logistic Regression: ~75-80% accuracy
- ‚úÖ Random Forest: ~78-85% accuracy
- ‚úÖ Best model selected and saved
- ‚úÖ Feature importance identified

---

### Day 3: Deployment & Testing

#### Morning Session (2-3 hours)

**3.1 Create Prediction Script**

Create `ml-layer/src/model_prediction.py`:

```python
"""
Win prediction script - loads model and makes predictions
"""
import sys
import pickle
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

from data_loader import CassandraDataLoader


class WinPredictor:
    """Win prediction for League of Legends matches"""
    
    def __init__(self, model_path='models/win_predictor_v1.pkl', 
                 scaler_path='models/feature_scaler.pkl'):
        """Load trained model and scaler"""
        
        # Get absolute paths
        model_path = Path(PROJECT_ROOT) / 'ml-layer' / model_path
        scaler_path = Path(PROJECT_ROOT) / 'ml-layer' / scaler_path
        
        # Load model
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
            self.model = model_data['model']
            self.feature_cols = model_data['feature_cols']
            self.model_name = model_data['model_name']
            self.accuracy = model_data['accuracy']
            logger.info(f"‚úÖ Loaded {self.model_name} (accuracy: {self.accuracy:.2%})")
            
        # Load scaler
        with open(scaler_path, 'rb') as f:
            self.scaler = pickle.load(f)
            logger.info(f"‚úÖ Loaded feature scaler")
            
    def predict(self, match_data: pd.DataFrame) -> Dict:
        """
        Predict win probability for match participants
        
        Args:
            match_data: DataFrame with participant data
            
        Returns:
            Dictionary with predictions and probabilities
        """
        # Ensure all required columns exist
        # (In production, add proper preprocessing here)
        
        # One-hot encode
        df_encoded = pd.get_dummies(match_data, 
                                     columns=['champion_name', 'position'],
                                     prefix=['champ', 'pos'])
        
        # Select features (add missing columns with 0)
        X = pd.DataFrame(0, index=df_encoded.index, columns=self.feature_cols)
        for col in df_encoded.columns:
            if col in X.columns:
                X[col] = df_encoded[col]
                
        # Scale numeric features
        # (Simplified - in production, identify numeric cols properly)
        
        # Predict
        predictions = self.model.predict(X)
        probabilities = self.model.predict_proba(X)
        
        return {
            'predictions': predictions.tolist(),
            'win_probabilities': probabilities[:, 1].tolist(),
            'loss_probabilities': probabilities[:, 0].tolist()
        }
        
    def predict_single(self, participant_data: Dict) -> Dict:
        """Predict for a single participant"""
        df = pd.DataFrame([participant_data])
        result = self.predict(df)
        
        return {
            'will_win': bool(result['predictions'][0]),
            'win_probability': result['win_probabilities'][0],
            'confidence': max(result['win_probabilities'][0], 
                             result['loss_probabilities'][0])
        }


def test_predictions():
    """Test predictions on sample data"""
    logger.info("üß™ Testing predictions...")
    
    # Load model
    predictor = WinPredictor()
    
    # Load test data from Cassandra
    loader = CassandraDataLoader()
    loader.connect()
    df = loader.load_match_participants(limit=10)
    loader.disconnect()
    
    logger.info(f"Loaded {len(df)} test samples")
    
    # Make predictions
    results = predictor.predict(df)
    
    # Display results
    print("\n" + "="*80)
    print("üéØ PREDICTION RESULTS (First 10 matches)")
    print("="*80)
    
    for i in range(len(df)):
        actual = df.iloc[i]['win']
        predicted = results['predictions'][i]
        probability = results['win_probabilities'][i]
        
        status = "‚úÖ CORRECT" if actual == predicted else "‚ùå WRONG"
        
        print(f"""
Match {i+1}: {df.iloc[i]['champion_name']} ({df.iloc[i]['position']})
  - Actual: {'WIN' if actual else 'LOSS'}
  - Predicted: {'WIN' if predicted else 'LOSS'} ({probability:.1%} confidence)
  - Status: {status}
        """)
    
    # Accuracy
    correct = sum(1 for i in range(len(df)) if df.iloc[i]['win'] == results['predictions'][i])
    accuracy = correct / len(df)
    
    print("="*80)
    print(f"‚úÖ Test Accuracy: {accuracy:.1%} ({correct}/{len(df)})")
    print("="*80 + "\n")
    
    
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Win prediction')
    parser.add_argument('--test', action='store_true', help='Run test predictions')
    
    args = parser.parse_args()
    
    if args.test:
        test_predictions()
    else:
        print("Usage: python model_prediction.py --test")
```

Test predictions:

```bash
python ml-layer/src/model_prediction.py --test
# Expected: Predictions on 10 samples with probabilities
```

#### Afternoon Session (2-3 hours)

**3.2 Create Verification Script**

Create `verify_phase5.py` in project root:

```python
"""
Phase 5 Verification Script - Verify ML Pipeline
"""
import os
import sys
from pathlib import Path
import subprocess

# Add ml-layer to path
sys.path.append(str(Path(__file__).parent / 'ml-layer' / 'src'))

def print_header(text):
    print(f"\n{'='*80}")
    print(f"  {text}")
    print(f"{'='*80}\n")


def test_1_ml_dependencies():
    """Test 1: Check ML package installations"""
    print_header("TEST 1: ML Dependencies")
    
    try:
        import sklearn
        import xgboost
        import mlflow
        import jupyter
        import matplotlib
        import seaborn
        import shap
        print("‚úÖ All ML packages installed")
        print(f"   - scikit-learn: {sklearn.__version__}")
        print(f"   - xgboost: {xgboost.__version__}")
        print(f"   - mlflow: {mlflow.__version__}")
        return True
    except ImportError as e:
        print(f"‚ùå Missing package: {e}")
        return False


def test_2_directory_structure():
    """Test 2: Check ml-layer directory structure"""
    print_header("TEST 2: Directory Structure")
    
    required_dirs = [
        'ml-layer',
        'ml-layer/notebooks',
        'ml-layer/src',
        'ml-layer/models',
        'ml-layer/config',
        'ml-layer/tests'
    ]
    
    all_exist = True
    for dir_path in required_dirs:
        exists = os.path.exists(dir_path)
        status = "‚úÖ" if exists else "‚ùå"
        print(f"{status} {dir_path}")
        if not exists:
            all_exist = False
            
    return all_exist


def test_3_notebooks():
    """Test 3: Check notebook files"""
    print_header("TEST 3: Notebooks")
    
    required_notebooks = [
        'ml-layer/notebooks/01_data_exploration.ipynb',
        'ml-layer/notebooks/02_feature_engineering.ipynb',
        'ml-layer/notebooks/03_model_training.ipynb'
    ]
    
    all_exist = True
    for notebook in required_notebooks:
        exists = os.path.exists(notebook)
        status = "‚úÖ" if exists else "‚ö†Ô∏è"
        print(f"{status} {notebook}")
        if not exists:
            all_exist = False
            
    return all_exist


def test_4_source_files():
    """Test 4: Check source Python files"""
    print_header("TEST 4: Source Files")
    
    required_files = [
        'ml-layer/src/__init__.py',
        'ml-layer/src/data_loader.py',
        'ml-layer/src/model_prediction.py'
    ]
    
    all_exist = True
    for file_path in required_files:
        exists = os.path.exists(file_path)
        status = "‚úÖ" if exists else "‚ùå"
        print(f"{status} {file_path}")
        if not exists:
            all_exist = False
            
    return all_exist


def test_5_saved_models():
    """Test 5: Check saved models"""
    print_header("TEST 5: Saved Models")
    
    model_files = [
        'ml-layer/models/win_predictor_v1.pkl',
        'ml-layer/models/feature_scaler.pkl'
    ]
    
    all_exist = True
    for file_path in model_files:
        exists = os.path.exists(file_path)
        if exists:
            size = os.path.getsize(file_path)
            print(f"‚úÖ {file_path} ({size:,} bytes)")
        else:
            print(f"‚ö†Ô∏è {file_path} (not created yet)")
            all_exist = False
            
    return all_exist


def test_6_data_loader():
    """Test 6: Test data loader connection"""
    print_header("TEST 6: Data Loader")
    
    try:
        from data_loader import CassandraDataLoader
        
        loader = CassandraDataLoader()
        loader.connect()
        
        df_participants, df_champions, df_positions = loader.load_all_data()
        
        loader.disconnect()
        
        print(f"‚úÖ Data loaded successfully:")
        print(f"   - Participants: {len(df_participants)} records")
        print(f"   - Champions: {len(df_champions)} records")
        print(f"   - Positions: {len(df_positions)} records")
        
        return True
    except Exception as e:
        print(f"‚ùå Data loader failed: {e}")
        return False


def test_7_model_prediction():
    """Test 7: Test model prediction"""
    print_header("TEST 7: Model Prediction")
    
    if not os.path.exists('ml-layer/models/win_predictor_v1.pkl'):
        print("‚ö†Ô∏è Model not trained yet")
        return False
        
    try:
        # Test prediction script
        result = subprocess.run(
            ['python', 'ml-layer/src/model_prediction.py', '--test'],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            print("‚úÖ Prediction script works")
            return True
        else:
            print(f"‚ùå Prediction script failed")
            print(result.stderr)
            return False
    except Exception as e:
        print(f"‚ùå Prediction test failed: {e}")
        return False


def test_8_documentation():
    """Test 8: Check documentation"""
    print_header("TEST 8: Documentation")
    
    docs = [
        'PHASE5_GUIDE.md',
        'PHASE5_READINESS_CHECK.md'
    ]
    
    all_exist = True
    for doc in docs:
        exists = os.path.exists(doc)
        status = "‚úÖ" if exists else "‚ö†Ô∏è"
        print(f"{status} {doc}")
        if not exists:
            all_exist = False
            
    return all_exist


def main():
    """Run all tests"""
    print("\n" + "üß™ PHASE 5 VERIFICATION".center(80, "="))
    print("Testing ML Pipeline".center(80))
    print("="*80)
    
    tests = [
        ("ML Dependencies", test_1_ml_dependencies),
        ("Directory Structure", test_2_directory_structure),
        ("Notebooks", test_3_notebooks),
        ("Source Files", test_4_source_files),
        ("Saved Models", test_5_saved_models),
        ("Data Loader", test_6_data_loader),
        ("Model Prediction", test_7_model_prediction),
        ("Documentation", test_8_documentation)
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"‚ùå {name} crashed: {e}")
            results.append((name, False))
    
    # Summary
    print_header("VERIFICATION SUMMARY")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "‚úÖ PASS" if result else "‚ö†Ô∏è NOT READY" if name in ["Notebooks", "Saved Models", "Model Prediction"] else "‚ùå FAIL"
        print(f"{status}: {name}")
    
    print(f"\n{'='*80}")
    print(f"  RESULT: {passed}/{total} tests passed ({passed/total*100:.0f}%)")
    print(f"{'='*80}\n")
    
    if passed == total:
        print("üéâ Phase 5 fully complete!")
    elif passed >= total * 0.5:
        print("‚ö†Ô∏è Phase 5 in progress - continue with remaining steps")
    else:
        print("‚ùå Phase 5 needs more work - review failed tests")


if __name__ == "__main__":
    main()
```

**3.3 Create Configuration File**

Create `ml-layer/config/ml_config.yaml`:

```yaml
# ML Pipeline Configuration

data:
  cassandra:
    contact_points: ['localhost']
    port: 9042
    keyspace: 'lol_data'
    
  train_test_split:
    test_size: 0.2
    random_state: 42
    
model:
  logistic_regression:
    max_iter: 1000
    random_state: 42
    
  random_forest:
    n_estimators: 100
    max_depth: 10
    random_state: 42
    n_jobs: -1
    
  cross_validation:
    cv_folds: 5
    
features:
  numeric:
    - kills
    - deaths
    - assists
    - gold_earned
    - total_damage_dealt
    - total_minions_killed
    - vision_score
    - gold_per_minute
    - damage_per_minute
    - cs_per_minute
    - kill_participation
    - kda_ratio
    - champion_win_rate
    - position_avg_gpm
    
  categorical:
    - champion_name
    - position
    
  time:
    - match_hour
    - match_day_of_week
    - is_weekend
    
  target: win
  
evaluation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
    
  target_accuracy: 0.75
  
paths:
  models: 'ml-layer/models'
  data_cache: 'ml-layer'
  notebooks: 'ml-layer/notebooks'
```

**3.4 Run Final Verification**

```bash
# Run verification
python verify_phase5.py

# Expected Results:
# - 5-6/8 tests passed initially (before notebooks completed)
# - 8/8 tests passed after full completion
```

---

## üìä Success Metrics

### MVP Completion Checklist

- [ ] ML dependencies installed (scikit-learn, xgboost, mlflow, jupyter)
- [ ] Directory structure created (ml-layer/ with subdirectories)
- [ ] Data loader working (connects to Cassandra, loads 500 records)
- [ ] Data exploration notebook completed (visualizations, correlations)
- [ ] Feature engineering notebook completed (~58 features created)
- [ ] Model training notebook completed (2 models trained)
- [ ] Model accuracy ‚â• 75% achieved
- [ ] Best model saved (win_predictor_v1.pkl)
- [ ] Prediction script working (can predict on new data)
- [ ] Verification script passing (‚â• 6/8 tests)
- [ ] Configuration file created (ml_config.yaml)
- [ ] Documentation complete (PHASE5_GUIDE.md)

### Model Performance Targets

**Minimum (MVP):**
- Accuracy: ‚â• 75%
- Precision: ‚â• 0.70
- Recall: ‚â• 0.70
- F1 Score: ‚â• 0.70

**Desired (Good):**
- Accuracy: ‚â• 80%
- Precision: ‚â• 0.75
- Recall: ‚â• 0.75
- F1 Score: ‚â• 0.75
- ROC-AUC: ‚â• 0.85

---

## üîß Troubleshooting

### Issue 1: Cassandra Connection Failed

**Error**: `NoHostAvailable` or `Connection refused`

**Solution**:
```bash
# Check Cassandra is running
docker ps | findstr cassandra

# Restart if needed
docker restart cassandra

# Wait for startup (30 seconds)
Start-Sleep -Seconds 30

# Test connection
docker exec cassandra cqlsh -e "DESC KEYSPACES;"
```

### Issue 2: Jupyter Not Starting

**Error**: `jupyter: command not found`

**Solution**:
```bash
# Ensure virtual environment activated
.\.venv\Scripts\Activate.ps1

# Reinstall jupyter
pip install --upgrade jupyter

# Start jupyter
cd ml-layer/notebooks
jupyter notebook
```

### Issue 3: Model Accuracy Too Low (<70%)

**Possible Causes**:
- Insufficient data (need more training samples)
- Feature engineering not optimal
- Model hyperparameters need tuning

**Solutions**:
1. Generate more data:
   ```bash
   python lol_match_generator.py --matches 100 --interval 0.1
   python batch-layer/src/batch_consumer.py --batches 2
   # Run PySpark ETL again to get 1000 samples
   ```

2. Try different features:
   - Add team composition features
   - Add player synergy features
   - Try polynomial features

3. Hyperparameter tuning:
   ```python
   from sklearn.model_selection import GridSearchCV
   
   param_grid = {
       'n_estimators': [50, 100, 200],
       'max_depth': [5, 10, 15],
       'min_samples_split': [2, 5, 10]
   }
   
   grid_search = GridSearchCV(rf_model, param_grid, cv=5)
   grid_search.fit(X_train, y_train)
   ```

### Issue 4: Predictions Too Slow

**Error**: Prediction takes > 1 second

**Solution**:
```python
# Use simpler model for production
# Or reduce features:
top_n_features = 20
feature_importance = rf_model.feature_importances_
top_indices = np.argsort(feature_importance)[-top_n_features:]
X_reduced = X[:, top_indices]
```

### Issue 5: Import Error in Notebooks

**Error**: `ModuleNotFoundError: No module named 'data_loader'`

**Solution**:
```python
# Add to first cell of notebook:
import sys
sys.path.append('../src')

# Or use absolute import:
from ml-layer.src.data_loader import CassandraDataLoader
```

---

## üìö Key Learnings

### What You'll Learn

1. **Machine Learning Pipeline**:
   - Data loading from NoSQL database
   - Feature engineering techniques
   - Model training and evaluation
   - Model deployment and prediction

2. **scikit-learn Ecosystem**:
   - LogisticRegression for baseline
   - RandomForestClassifier for advanced model
   - StandardScaler for feature scaling
   - train_test_split for data splitting
   - cross_val_score for validation
   - Metrics: accuracy, precision, recall, F1, ROC-AUC

3. **Data Science Best Practices**:
   - Exploratory Data Analysis (EDA)
   - Feature correlation analysis
   - Train/test split strategy
   - Cross-validation
   - Model comparison
   - Feature importance analysis

4. **Jupyter Notebooks**:
   - Interactive data exploration
   - Visualization with matplotlib/seaborn
   - Reproducible analysis
   - Documentation in markdown cells

---

## üöÄ Next Steps After MVP

Once MVP is complete and working, consider these expansions:

### Week 8-9: Advanced Features

1. **Add MLflow Tracking**:
   ```bash
   # Start MLflow server
   mlflow server --host 127.0.0.1 --port 5000
   
   # Track experiments in notebook
   import mlflow
   mlflow.set_experiment("lol_win_prediction")
   
   with mlflow.start_run():
       mlflow.log_params({"n_estimators": 100, "max_depth": 10})
       mlflow.log_metrics({"accuracy": 0.85, "f1": 0.83})
       mlflow.sklearn.log_model(model, "random_forest")
   ```

2. **Build Prediction API**:
   ```python
   # ml-layer/api/prediction_api.py
   from flask import Flask, request, jsonify
   from model_prediction import WinPredictor
   
   app = Flask(__name__)
   predictor = WinPredictor()
   
   @app.route('/predict', methods=['POST'])
   def predict():
       data = request.json
       result = predictor.predict_single(data)
       return jsonify(result)
   
   if __name__ == '__main__':
       app.run(host='0.0.0.0', port=5001)
   ```

3. **Integrate with Streaming Layer**:
   - Read from Kafka in real-time
   - Make predictions on live matches
   - Write predictions to Elasticsearch
   - Display in Kibana dashboard

4. **Batch Prediction Pipeline**:
   - Schedule daily predictions
   - Store results in Cassandra
   - Track prediction accuracy over time
   - Detect model drift

---

## üìù Phase 5 Deliverables Summary

```
‚úÖ Completed:
- ML environment setup
- Data exploration (EDA)
- Feature engineering (~58 features)
- Model training (Logistic Regression + Random Forest)
- Model evaluation (accuracy, precision, recall, F1, ROC-AUC)
- Best model selection and saving
- Prediction script
- Verification script
- Configuration file
- Complete documentation

üì¶ Files Created:
ml-layer/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb      ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb   ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ 03_model_training.ipynb        ‚úÖ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                    ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py                 ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ model_prediction.py            ‚úÖ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ win_predictor_v1.pkl           ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ feature_scaler.pkl             ‚úÖ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ ml_config.yaml                 ‚úÖ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py                    ‚úÖ
‚îî‚îÄ‚îÄ requirements.txt                   ‚úÖ

verify_phase5.py                       ‚úÖ
PHASE5_GUIDE.md                        ‚úÖ
```

---

## üéØ Final Checklist

Before marking Phase 5 complete, verify:

- [ ] All dependencies installed without errors
- [ ] Jupyter notebooks run end-to-end without errors
- [ ] Model achieves ‚â• 75% accuracy
- [ ] Prediction script works on test data
- [ ] verify_phase5.py passes ‚â• 6/8 tests
- [ ] All files committed to Git
- [ ] PLANMODE.md updated with completion status
- [ ] Ready to proceed to Phase 6 (Monitoring)

---

**Created**: January 13, 2026  
**Version**: 1.0 - Option A (Simple MVP)  
**Author**: GitHub Copilot  
**Estimated Time**: 2-3 days  
**Difficulty**: Intermediate
