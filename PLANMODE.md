# PLANMODE - Big Data Learning Experience System

## Dá»± Ã¡n: Há»‡ thá»‘ng Big Data xá»­ lÃ½ dá»¯ liá»‡u Game LoL

---

## ğŸ“‹ Tá»”NG QUAN Dá»° ÃN

### Má»¥c tiÃªu

XÃ¢y dá»±ng há»‡ thá»‘ng Big Data xá»­ lÃ½ real-time vÃ  batch data tá»« tráº­n Ä‘áº¥u LoL, phá»¥c vá»¥:

- PhÃ¢n tÃ­ch real-time (streaming)
- LÆ°u trá»¯ lá»‹ch sá»­ (data lake)
- Machine Learning prediction
- Visualization dashboard

### Kiáº¿n trÃºc Lambda Architecture

- **Speed Layer**: Kafka â†’ Spark Streaming â†’ Elasticsearch â†’ Kibana
- **Batch Layer**: Kafka â†’ HDFS â†’ PySpark â†’ Cassandra â†’ ML Model

---

## ğŸ—‚ï¸ PHASE 1: SETUP INFRASTRUCTURE (Week 1-2)

(SETUP_GUILDE)

### 1.1 MÃ´i trÆ°á»ng phÃ¡t triá»ƒn

- [ ] Setup Docker containers cho táº¥t cáº£ services
- [ ] Cáº¥u hÃ¬nh Kafka cluster (3 brokers, 3 partitions)
- [ ] Setup Hadoop cluster (HDFS + YARN)
- [ ] CÃ i Ä‘áº·t Spark (Streaming + Batch)
- [ ] Setup Elasticsearch cluster
- [ ] CÃ i Ä‘áº·t Kibana
- [ ] Setup Cassandra cluster
- [ ] Cáº¥u hÃ¬nh networking giá»¯a cÃ¡c services

### 1.2 Development tools

- [ ] Git repository structure
- [ ] Python virtual environment
- [ ] Jupyter Notebook cho exploration
- [ ] Monitoring tools (Prometheus + Grafana)
- [ ] Log aggregation (ELK Stack)

---

## ğŸ”§ PHASE 2: DATA INGESTION LAYER (Week 3) âœ… **COMPLETED**

### 2.1 Data Generator âœ…

- [x] Táº¡o `lol_match_generator.py` - **COMPLETED**

  - Generate fake match data theo Riot API format
  - Thay tháº¿ crawl tá»« op.gg (do CSS changes)
  - Continuous generation mode (infinite loop)
  - Kafka Producer integration
  - Configurable interval (default: 0.5s/match)
  - Realistic match statistics:
    - 10 participants (5v5)
    - Champion pool (36 champions)
    - Position-based team structure
    - Win/loss determination
    - Stats: kills, deaths, assists, gold, damage, CS, vision

- [x] Refactor vÃ o module structure - **COMPLETED**
  - Organized code in `data-generator/` folder
  - Configuration file (YAML)
  - Logging system
  - Unit tests (pytest)
  - CLI arguments support
  - Batch and continuous modes

### 2.2 Kafka Setup âœ…

- [x] Topic configuration: `lol_matches`
- [x] Partition strategy (3 partitions)
- [x] Retention policy (configured in docker-compose)
- [x] Producer integration with compression (gzip)
- [x] Verified with end-to-end testing

### 2.3 Testing & Verification âœ…

- [x] Unit tests cho generator module
- [x] Integration tests cho Kafka flow
- [x] End-to-end verification script
- [x] All tests passed (13/13)

**How to Run Tests:**

```bash
#Run Phase 2 verification (comprehensive)

python verify_phase2.py

```

**Phase 2 Verification Results:**

```
âœ“ 13/13 tests passed
âœ“ Data Ingestion Layer working correctly
âœ“ Ready for Phase 3: Streaming Layer
```

**Current Implementation:**

```python
# data-generator/src/generator.py features:
- Format: Riot API v2 compatible
- Kafka Topic: 'lol_matches' (configurable via YAML)
- Bootstrap Server: localhost:29092 (external port)
- Generation Rate: 2 matches/second (configurable)
- Modes: Continuous & Batch
- Compression: gzip
- Logging: File + Console
```

**Deliverables:**

```
data-generator/  âœ… COMPLETED
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py              âœ… Module initialization
â”‚   â””â”€â”€ generator.py             âœ… Main generator class
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              âœ… Configuration file
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_generator.py        âœ… Unit tests (7 tests)
â”œâ”€â”€ logs/                        âœ… Auto-created log directory
â””â”€â”€ README.md                    âœ… Documentation

verify_phase2.py                 âœ… Comprehensive verification script
â”œâ”€â”€ 7 automated tests:
â”‚   âœ… Kafka connection
â”‚   âœ… Topic configuration
â”‚   âœ… Producer functionality
â”‚   âœ… Consumer functionality
â”‚   âœ… Generator module import
â”‚   âœ… Match data format validation
â”‚   â””â”€â”€ âœ… End-to-end data flow
â””â”€â”€ Status: ALL TESTS PASSED

Production files:
â”œâ”€â”€ submit_spark_job.ps1            âœ… Spark job submission script
â”œâ”€â”€ verify_phase3_production.py    âœ… Production deployment tests
â””â”€â”€ PHASE3_QUICKSTART.md          âœ… 5-minute deployment guide
```

---

## âš¡ PHASE 3: STREAMING LAYER (Week 4-5) âœ… **COMPLETED** (Including Kibana)

### 3.1 Spark Streaming Consumer âœ…

- [x] Setup Spark Structured Streaming vá»›i Kafka
- [x] Xá»­ lÃ½ micro-batches tá»« Kafka stream
- [x] Parse JSON match data
- [x] Extract participants vá»›i real-time metrics
- [x] TÃ­nh toÃ¡n derived metrics:
  - KDA (Kills/Deaths/Assists ratio)
  - Gold per minute
  - Damage per minute
  - CS per minute

### 3.2 Elasticsearch Integration âœ…

- [x] Index mapping design vá»›i time-series fields
- [x] ElasticsearchIndexer class vá»›i bulk indexing
- [x] Document preparation vÃ  validation
- [x] Connection management vÃ  error handling

### 3.3 Data Processing âœ…

- [x] Match data parser (JSON â†’ Participants)
- [x] Derived metrics calculator
- [x] Elasticsearch document formatter
- [x] Batch processing with foreachBatch

### 3.4 Configuration Files âœ…

- [x] spark_config.yaml (Spark & Kafka settings)
- [x] es_mapping.json (Elasticsearch index mapping)
- [x] Checkpoint location setup

### 3.5 Testing & Verification âœ…

- [x] Comprehensive verification script
- [x] 7 automated test suites (22 assertions)
- [x] All tests passed
- [x] End-to-end pipeline verified (Generator â†’ Kafka â†’ Spark â†’ Elasticsearch)
- [x] Production deployment on Docker cluster

### 3.6 Production Deployment âœ…

- [x] Spark job submission via PowerShell script
- [x] Checkpoint management for fault tolerance
- [x] Kafka cluster health monitoring
- [x] Spark UI accessible at http://localhost:4040
- [x] Real-time indexing to Elasticsearch (29,915+ documents)

### 3.7 Kibana Dashboard Setup âœ… **COMPLETED**

- [x] Access Kibana UI at http://localhost:5601
- [x] Create index pattern for `lol_matches_stream`
- [x] Configure time field (@timestamp or timestamp)
- [x] Create visualizations:
  - [x] Document count over time (line chart)
  - [x] Win rate by champion (pie chart)
  - [x] Average KDA by position (bar chart)
  - [x] Gold per minute distribution (histogram)
- [x] Build real-time dashboard
- [x] Verify live data updates (auto-refresh)
- [x] Save and export dashboard configuration

**How to Run & Verify:**

```bash
# Step 1: Run automated tests
python verify_phase3.py
# Expected: âœ“ 22/22 tests passed

# Step 2: Start data generator (new window)
python data-generator/src/generator.py --mode continuous
# Expected: Generating 2 matches/second to Kafka

# Step 3: Submit Spark job (Docker cluster)
.\submit_spark_job.ps1
# Expected: Job starts, SparkUI at port 4040

# Step 4: Verify Spark UI accessible
# Open browser: http://localhost:4040
# Check: Streaming tab shows active query

# Step 5: Check Elasticsearch document count
curl "http://localhost:9200/lol_matches_stream/_count?pretty"
# Expected: Count increasing every ~5 seconds

# Step 6: Monitor Spark Master UI
# Open browser: http://localhost:8080
# Check: Running Applications shows LoL_Match_Streaming

# Step 7: Setup Kibana Dashboard
# Open browser: http://localhost:5601
# Follow: KIBANA_SETUP_GUIDE.md for detailed steps

# Step 8: Verify live data in Kibana
# Dashboard should show data updating in real-time
```

**Phase 3 Verification Results:**

```
âœ“ 22/22 tests passed
âœ“ Streaming Layer properly configured
âœ“ Production deployment successful
âœ“ Spark Application UI: http://localhost:4040 âœ…
âœ“ Elasticsearch: 30,000+ documents indexed âœ…
âœ“ Pipeline: Generator â†’ Kafka â†’ Spark â†’ ES âœ…
âœ“ Kibana Dashboard: Live data visualization âœ…
âœ“ PHASE 3 COMPLETED
```

**Current Implementation:**

```python
# Technology Stack:
- Spark Structured Streaming API (3.5.0)
- Kafka Source: localhost:29092, topic 'lol_matches'
- Elasticsearch Sink: localhost:9200, index 'lol_matches_stream'
- Batch Processing: foreachBatch with derived metrics
- Checkpoint: checkpoints/streaming/

# Features:
- Real-time data ingestion from Kafka
- Automatic schema parsing (Riot API v2)
- Participant extraction and flattening
- Derived metrics calculation (KDA, GPM, DPM, CSPM)
- Bulk indexing to Elasticsearch (with error handling)
```

**Deliverables:**

```
streaming-layer/  âœ… COMPLETED
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                      âœ… Module initialization
â”‚   â”œâ”€â”€ spark_streaming_consumer.py      âœ… Structured Streaming consumer
â”‚   â”œâ”€â”€ elasticsearch_indexer.py         âœ… ES client with bulk indexing
â”‚   â””â”€â”€ processors.py                    âœ… Data processing functions
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ spark_config.yaml                âœ… Spark configuration
â”‚   â””â”€â”€ es_mapping.json                  âœ… ES index mapping
â””â”€â”€ tests/
    â””â”€â”€ (Unit tests TBD)

verify_phase3.py                         âœ… Comprehensive verification
â”œâ”€â”€ 7 test suites:
â”‚   âœ… Elasticsearch connection & health
â”‚   âœ… ES index setup with mapping
â”‚   âœ… ES indexing functionality (single & bulk)
â”‚   âœ… Kafka connection for Spark
â”‚   âœ… Configuration files validation
â”‚   âœ… Module imports
â”‚   â””â”€â”€ âœ… Data processors logic
â””â”€â”€ Status: ALL TESTS PASSED

PHASE3_GUIDE.md                          âœ… Complete implementation guide
KIBANA_SETUP_GUIDE.md                    ğŸ”„ Kibana dashboard setup (NEW)
```

**Phase 3 Completion Criteria:**
âœ… Spark Streaming running  
âœ… Elasticsearch indexing  
âœ… Kibana Dashboard showing live data  
âœ… **PHASE 3 FULLY COMPLETED - Ready for Phase 4**

### 3.7 Common Issues & Solutions âœ…

#### Issue 1: Kafka Container Keeps Restarting

**Symptom**: `docker compose ps` khÃ´ng hiá»ƒn thá»‹ Kafka container

**Root Cause**: Cluster ID mismatch giá»¯a Kafka metadata vÃ  Zookeeper

**Error Log**:

```
InconsistentClusterIdException: The Cluster ID Or8zQec0Sgyru-dkddFCvQ
doesn't match stored clusterId Some(6r9_qcVoTuCw7V6yvDjAqA)
```

**Solution**:

```powershell
# Remove corrupted Kafka volumes
docker compose down -v kafka
docker volume rm bigbig_kafka_data

# Recreate Kafka with fresh metadata
docker compose up -d kafka

# Wait for Kafka to start (check logs)
docker logs kafka --tail 50

# Recreate topic
docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic lol_matches --partitions 3 --replication-factor 1

# Verify topic
docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --describe --topic lol_matches
```

#### Issue 2: Spark Job Crashes with Offset Error

**Symptom**: `IllegalStateException: offset was changed from 383 to 28`

**Root Cause**: Checkpoint chá»©a offset cÅ© khÃ´ng khá»›p vá»›i Kafka topic má»›i (sau khi recreate)

**Error Log**:

```
Query terminated with error. Partition lol_matches-2's offset was
changed from 383 to 28, some data may have been missed.
failOnDataLoss triggered
```

**Solution**:

```powershell
# Clear old checkpoints
Remove-Item -Recurse -Force .\checkpoints\streaming\* -ErrorAction SilentlyContinue

# Resubmit Spark job
.\submit_spark_job.ps1

# Verify job starts without errors
docker logs spark-master --tail 50
```

#### Issue 3: Spark UI Not Accessible

**Symptom**: Cannot access http://localhost:4040 or 4041

**Root Cause**: No active Spark application running

**Solution**:

```powershell
# Check if Spark job process exists
docker exec spark-master ps aux | Select-String "spark_streaming_consumer"

# If empty output, job not running - restart:
# 1. Start data generator (provides data stream)
Start-Process powershell -ArgumentList "-NoExit", "-Command", \
  "cd 'E:\FILEMANAGEMENT_PC\_WORKSPACE\PROGRESS\bigbig'; \
  .\.venv\Scripts\Activate.ps1; \
  python data-generator/src/generator.py --mode continuous"

# 2. Wait 3 seconds for generator to start
Start-Sleep -Seconds 3

# 3. Submit Spark job
.\submit_spark_job.ps1

# 4. Wait 15-20 seconds for UI to initialize
Start-Sleep -Seconds 15

# 5. Test UI accessibility
curl http://localhost:4040

# If successful, open browser to http://localhost:4040
```

**Prevention Tips**:

- Always check `docker compose ps` before troubleshooting
- Keep data generator running when testing Spark
- Clear checkpoints when recreating Kafka topics
- Monitor Spark logs for initialization errors
- Use `docker logs <container>` for debugging

---

## ğŸ“¦ PHASE 4: BATCH LAYER (Week 6-7)

### 4.1 Batch Consumer

- [ ] Kafka consumer láº¥y 50 messages/batch
- [ ] LÆ°u vÃ o HDFS vá»›i partition theo ngÃ y
- [ ] Compression vÃ  format optimization (Parquet)
- [ ] Checkpoint mechanism

### 4.2 HDFS Organization

- [ ] Directory structure: `/data/lol_matches/YYYY/MM/DD/`
- [ ] File naming convention
- [ ] Retention policy
- [ ] Backup strategy

### 4.3 Batch Processing (PySpark)

- [ ] ETL pipeline tá»« HDFS
- [ ] Data cleaning vÃ  transformation
- [ ] Feature engineering cho ML
- [ ] Aggregation jobs
- [ ] Write to Cassandra

### 4.4 Cassandra Storage

- [ ] Keyspace design: `lol_data`
- [ ] Table schema: `match_participants`
- [ ] Partition key strategy
- [ ] Query optimization

**Deliverables:**

```
batch-layer/
â”œâ”€â”€ batch_consumer.py
â”œâ”€â”€ pyspark_etl.py
â”œâ”€â”€ cassandra_writer.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ hdfs_config.yaml
â”‚   â””â”€â”€ cassandra_schema.cql
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ analytics_queries.sql
â””â”€â”€ tests/
    â””â”€â”€ test_batch_processing.py
```

---

## ğŸ¤– PHASE 5: MACHINE LEARNING LAYER (Week 8-9)

### 5.1 Feature Engineering

- [ ] Extract features tá»« Cassandra
- [ ] Feature selection
- [ ] Feature scaling vÃ  normalization
- [ ] Handle imbalanced data

### 5.2 Model Development

- [ ] Random Forest classifier
- [ ] Model training pipeline
- [ ] Hyperparameter tuning
- [ ] Cross-validation
- [ ] Feature importance analysis

### 5.3 Model Deployment

- [ ] Model versioning (MLflow)
- [ ] Prediction API
- [ ] A/B testing framework
- [ ] Model monitoring

### 5.4 Prediction Integration

- [ ] Real-time prediction tá»« streaming data
- [ ] Batch prediction
- [ ] Result storage
- [ ] Performance metrics

**Deliverables:**

```
ml-layer/
â”œâ”€â”€ feature_engineering.py
â”œâ”€â”€ model_training.py
â”œâ”€â”€ model_prediction.py
â”œâ”€â”€ model_evaluation.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ random_forest_v1.pkl
â”‚   â””â”€â”€ feature_scaler.pkl
â”œâ”€â”€ mlflow/
â”‚   â””â”€â”€ experiment_tracking.py
â””â”€â”€ tests/
    â””â”€â”€ test_ml_pipeline.py
```

---

## ğŸ“Š PHASE 6: MONITORING & OPTIMIZATION (Week 10)

### 6.1 Monitoring Stack

- [ ] Prometheus metrics collection
- [ ] Grafana dashboards:
  - Kafka lag monitoring
  - Spark job metrics
  - ES query performance
  - Cassandra throughput
  - ML model performance

### 6.2 Performance Tuning

- [ ] Kafka throughput optimization
- [ ] Spark memory tuning
- [ ] ES index optimization
- [ ] Cassandra query tuning
- [ ] HDFS replication factor

### 6.3 Alerting

- [ ] Consumer lag alerts
- [ ] Data quality alerts
- [ ] System health alerts
- [ ] ML model drift detection

**Deliverables:**

```
monitoring/
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ alerts/
â””â”€â”€ scripts/
    â””â”€â”€ health_check.py
```

---

## ğŸ§ª PHASE 7: TESTING & DOCUMENTATION (Week 11)

### 7.1 Testing

- [ ] Unit tests (pytest)
- [ ] Integration tests
- [ ] End-to-end tests
- [ ] Load testing (JMeter/Locust)
- [ ] Data quality tests

### 7.2 Documentation

- [ ] Architecture documentation
- [ ] API documentation
- [ ] Deployment guide
- [ ] User manual
- [ ] Troubleshooting guide

**Deliverables:**

```
docs/
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ system_design.md
â”‚   â””â”€â”€ data_flow.md
â”œâ”€â”€ api/
â”‚   â””â”€â”€ api_reference.md
â”œâ”€â”€ deployment/
â”‚   â””â”€â”€ deployment_guide.md
â””â”€â”€ guides/
    â”œâ”€â”€ user_guide.md
    â””â”€â”€ troubleshooting.md
```

---

## ğŸš€ PHASE 8: DEPLOYMENT & MAINTENANCE (Week 12)

### 8.1 Deployment

- [ ] Docker Compose production setup
- [ ] Kubernetes manifests (optional)
- [ ] CI/CD pipeline (Jenkins/GitLab CI)
- [ ] Blue-green deployment
- [ ] Rollback procedures

### 8.2 Production Readiness

- [ ] Security hardening
- [ ] Backup automation
- [ ] Disaster recovery plan
- [ ] Capacity planning
- [ ] SLA definition

---

## ğŸ¯ SUCCESS METRICS

### Technical Metrics

- Kafka throughput: â‰¥ 10k messages/sec
- Spark Streaming latency: < 1 minute
- ES query response: < 100ms
- Cassandra write throughput: â‰¥ 5k writes/sec
- ML model accuracy: â‰¥ 75%

### Business Metrics

- Real-time dashboard updates: < 30s delay
- Historical data retention: 1 year
- System uptime: 99.9%
- Data quality score: â‰¥ 95%

---

## ğŸ“š LEARNING OBJECTIVES

Sau khi hoÃ n thÃ nh dá»± Ã¡n, báº¡n sáº½ náº¯m vá»¯ng:

1. **Stream Processing**: Kafka, Spark Streaming
2. **Batch Processing**: Hadoop, HDFS, PySpark
3. **Search & Analytics**: Elasticsearch, Kibana
4. **NoSQL Database**: Cassandra
5. **Machine Learning**: Feature engineering, Random Forest, MLflow
6. **DevOps**: Docker, Monitoring, CI/CD
7. **Data Engineering**: ETL pipelines, Data modeling
8. **System Design**: Lambda architecture, Scalability

---

## ğŸ› ï¸ RESOURCE REQUIREMENTS

### Hardware (Development)

- CPU: 8+ cores
- RAM: 32GB minimum
- Storage: 500GB SSD
- Network: Stable internet

### Cloud Alternative (AWS)

- EC2: m5.2xlarge (4 instances)
- S3: For data lake
- EMR: For Spark jobs
- MSK: Managed Kafka
- OpenSearch: Managed Elasticsearch

### Software Licenses

- All open-source (no licensing cost)
- Optional: Confluent Platform (Kafka)
- Optional: Databricks (Spark)

---

## ğŸ“… TIMELINE SUMMARY

| Phase     | Duration     | Key Deliverables        |
| --------- | ------------ | ----------------------- |
| Phase 1   | 2 weeks      | Infrastructure setup    |
| Phase 2   | 1 week       | Data generator & Kafka  |
| Phase 3   | 2 weeks      | Streaming pipeline      |
| Phase 4   | 2 weeks      | Batch pipeline          |
| Phase 5   | 2 weeks      | ML pipeline             |
| Phase 6   | 1 week       | Monitoring setup        |
| Phase 7   | 1 week       | Testing & Docs          |
| Phase 8   | 1 week       | Deployment              |
| **Total** | **12 weeks** | Production-ready system |

---

## ğŸ“ NEXT STEPS

1. **Review & Approve**: Xem xÃ©t plan nÃ y vÃ  Ä‘iá»u chá»‰nh náº¿u cáº§n
2. **Setup Git**: Táº¡o repository vá»›i cáº¥u trÃºc codebase
3. **Start Phase 1**: Báº¯t Ä‘áº§u setup Docker vÃ  infrastructure
4. **Daily Standups**: Track progress hÃ ng ngÃ y
5. **Weekly Reviews**: Review káº¿t quáº£ má»—i tuáº§n

---

**Created**: January 12, 2026
**Version**: 1.0
**Author**: GitHub Copilot
