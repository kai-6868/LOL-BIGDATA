# ğŸš€ PHáº¦N 2: BATCH PROCESSING LAYER

## ğŸ“‹ Tá»•ng quan

Pipeline batch xá»­ lÃ½ dá»¯ liá»‡u theo luá»“ng:

```
Kafka â†’ Batch Consumer â†’ HDFS (Parquet) â†’ PySpark ETL â†’ Cassandra
```

### CÃ¡c thÃ nh pháº§n:
- **Batch Consumer**: Äá»c data tá»« Kafka theo batch
- **HDFS**: LÆ°u trá»¯ data dáº¡ng Parquet (columnar format)
- **PySpark ETL**: Transform vÃ  aggregate data
- **Cassandra**: NoSQL database cho historical data

---

## ğŸ¯ YÃªu cáº§u

### ÄÃ£ hoÃ n thÃ nh Part 1
- âœ… Kafka Ä‘ang cháº¡y vá»›i data
- âœ… Docker containers running
- âœ… Data generator Ä‘ang táº¡o data

### Containers cáº§n thiáº¿t
- âœ… `namenode` (HDFS)
- âœ… `datanode` (HDFS)
- âœ… `cassandra`
- âœ… `kafka`

---

## ğŸš€ QUICK START (Recommended)

### Option 1: Run All Steps Automatically

```powershell
.\run_batch_complete.ps1
```

Script nÃ y sáº½ tá»± Ä‘á»™ng:
1. âœ… Setup HDFS directories
2. âœ… Setup Cassandra schema
3. âœ… Run batch consumer
4. âœ… Run PySpark ETL

**Thá»i gian**: ~2-3 phÃºt

---

## ğŸ“ MANUAL SETUP (Step by Step)

Náº¿u muá»‘n cháº¡y tá»«ng bÆ°á»›c riÃªng:

### BÆ°á»›c 1: Setup HDFS

```powershell
.\setup_hdfs.ps1
```

**Script nÃ y sáº½**:
- Táº¡o `/data/lol_matches` directory
- Set permissions 777
- Táº¡o partition theo ngÃ y hiá»‡n táº¡i

### BÆ°á»›c 2: Setup Cassandra

```powershell
.\setup_cassandra.ps1
```

**Script nÃ y sáº½**:
- Copy `init_cassandra.cql` vÃ o container
- Execute CQL script
- Verify schema created

### BÆ°á»›c 3: Run Batch Consumer

```powershell
.\run_batch_consumer.ps1 -Batches 1 -BatchSize 50
```

**Parameters**:
- `-Batches`: Sá»‘ lÆ°á»£ng batches (default: 1)
- `-BatchSize`: Messages per batch (default: 50)

**Script nÃ y sáº½**:
- Consume data tá»« Kafka
- Write Parquet files vÃ o HDFS
- Partition theo date (YYYY/MM/DD)

### BÆ°á»›c 4: Run PySpark ETL

```powershell
.\run_batch_etl.ps1 -Date "2026/01/15"
```

**Parameters**:
- `-Date`: Date to process (default: today)

**Script nÃ y sáº½**:
- Read Parquet tá»« HDFS
- Transform vÃ  aggregate
- Write vÃ o Cassandra

---

## âœ… Verification

### Check HDFS Data

```powershell
# List all files
docker exec namenode hdfs dfs -ls -R /data/lol_matches

# Check file size
docker exec namenode hdfs dfs -du -h /data/lol_matches

# View file content (first few rows)
docker exec namenode hdfs dfs -cat /data/lol_matches/2026/01/15/*.parquet | head -n 10
```

### Check Cassandra Data

```powershell
# Connect to Cassandra
docker exec -it cassandra cqlsh

# Query data
USE lol_data;
SELECT COUNT(*) FROM match_stats;
SELECT * FROM match_stats LIMIT 5;

# Exit
exit;
```

---

## ğŸ” Troubleshooting

### Issue 1: HDFS Permission Denied

**Error**:
```
PermissionError: Permission denied writing to HDFS
```

**Solution**:
```powershell
docker exec namenode hdfs dfs -chmod -R 777 /data/lol_matches
```

### Issue 2: Cassandra Connection Failed

**Error**:
```
NoHostAvailable: Unable to connect to Cassandra
```

**Solution**:
```powershell
# Check Cassandra is running
docker exec cassandra nodetool status

# Restart if needed
docker-compose restart cassandra
Start-Sleep -Seconds 30

# Re-run setup
.\setup_cassandra.ps1
```

### Issue 3: No Data in Kafka

**Error**:
```
Batch timeout reached. Got 0/50 messages
```

**Solution**:
- Ensure Data Generator is running (Part 1)
- Check Kafka has data:
```powershell
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic lol_matches --max-messages 1
```

### Issue 4: HDFS Path Not Found

**Error**:
```
FileNotFoundError: HDFS path not found
```

**Solution**:
```powershell
# Re-run HDFS setup
.\setup_hdfs.ps1

# Or manually create
docker exec namenode hdfs dfs -mkdir -p /data/lol_matches/$(Get-Date -Format "yyyy/MM/dd")
docker exec namenode hdfs dfs -chmod 777 /data/lol_matches/$(Get-Date -Format "yyyy/MM/dd")
```

### Issue 5: Python Module Not Found

**Error**:
```
ModuleNotFoundError: No module named 'hdfs'
```

**Solution**:
```powershell
# Activate venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“Š Complete Workflow (Part 1 + Part 2)

### Terminal 1: Data Generator (Part 1)
```powershell
.\.venv\Scripts\Activate.ps1
python lol_match_generator.py
```

### Terminal 2: Spark Streaming (Part 1)
```powershell
.\submit_spark_job.ps1
```

### Terminal 3: Batch Processing (Part 2)
```powershell
# One-time setup
.\setup_hdfs.ps1
.\setup_cassandra.ps1

# Run periodically (e.g., every 5 minutes)
.\run_batch_consumer.ps1 -Batches 1
.\run_batch_etl.ps1
```

---

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Batch size | 50 messages |
| Batch timeout | 60 seconds |
| HDFS write time | ~1-2 seconds/batch |
| Parquet file size | ~50-100 KB/batch |
| ETL processing time | ~5-10 seconds/batch |
| Cassandra write time | ~2-3 seconds/batch |
| Total time per batch | ~10-15 seconds |

---

## ğŸ¯ Success Criteria

Batch layer cháº¡y thÃ nh cÃ´ng khi:

- âœ… HDFS directories created vá»›i permissions Ä‘Ãºng
- âœ… Cassandra schema initialized
- âœ… Batch consumer Ä‘á»c data tá»« Kafka
- âœ… Parquet files Ä‘Æ°á»£c lÆ°u vÃ o HDFS
- âœ… PySpark ETL process data thÃ nh cÃ´ng
- âœ… Data Ä‘Æ°á»£c ghi vÃ o Cassandra
- âœ… Query Cassandra tháº¥y data

---

## ğŸ’¡ Tips & Best Practices

### 1. Automated Batch Processing

Táº¡o scheduled task Ä‘á»ƒ cháº¡y batch processing tá»± Ä‘á»™ng:

```powershell
# Windows Task Scheduler
# Run every 5 minutes:
.\run_batch_consumer.ps1 -Batches 1
.\run_batch_etl.ps1
```

### 2. Monitor HDFS Space

```powershell
# Check HDFS usage
docker exec namenode hdfs dfs -df -h

# Clean old data (older than 30 days)
docker exec namenode hdfs dfs -rm -r /data/lol_matches/2025/*
```

### 3. Partition Strategy

Data Ä‘Æ°á»£c partition theo date:
```
/data/lol_matches/
  â”œâ”€â”€ 2026/
  â”‚   â”œâ”€â”€ 01/
  â”‚   â”‚   â”œâ”€â”€ 15/
  â”‚   â”‚   â”‚   â”œâ”€â”€ matches_20260115_100000_batch1.parquet
  â”‚   â”‚   â”‚   â”œâ”€â”€ matches_20260115_100500_batch2.parquet
```

Lá»£i Ã­ch:
- âœ… Dá»… query historical data
- âœ… Dá»… delete old data
- âœ… Optimize ETL performance

### 4. Backup Cassandra

```powershell
# Create snapshot
docker exec cassandra nodetool snapshot lol_data

# List snapshots
docker exec cassandra nodetool listsnapshots
```

### 5. Monitor Logs

```powershell
# Batch consumer logs
cat batch-layer/logs/batch_consumer_$(Get-Date -Format "yyyyMMdd").log

# Cassandra logs
docker logs cassandra --tail 100

# HDFS logs
docker logs namenode --tail 100
```

---

## ğŸ“ Scripts Summary

| Script | Purpose | Usage |
|--------|---------|-------|
| `run_batch_complete.ps1` | **Run all steps** | `.\run_batch_complete.ps1` |
| `setup_hdfs.ps1` | Setup HDFS | `.\setup_hdfs.ps1` |
| `setup_cassandra.ps1` | Setup Cassandra | `.\setup_cassandra.ps1` |
| `run_batch_consumer.ps1` | Kafka â†’ HDFS | `.\run_batch_consumer.ps1 -Batches 1` |
| `run_batch_etl.ps1` | HDFS â†’ Cassandra | `.\run_batch_etl.ps1 -Date "2026/01/15"` |

---

## ğŸš€ Next Steps

Sau khi hoÃ n thÃ nh Part 2:

1. **Verify data flow**:
   - Kafka â†’ HDFS â†’ Cassandra
   - Check data consistency

2. **Optimize performance**:
   - Adjust batch size
   - Tune Spark configs

3. **Setup monitoring**:
   - Track batch processing metrics
   - Alert on failures

4. **Move to Part 3**: Machine Learning Layer

---

**ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰**

Náº¿u gáº·p váº¥n Ä‘á», check pháº§n Troubleshooting hoáº·c xem logs Ä‘á»ƒ debug.
